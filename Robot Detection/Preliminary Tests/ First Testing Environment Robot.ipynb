{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1\n",
    "**Reading in images that have a robot in them**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "positiveImages=[]\n",
    "files=os.listdir(\"positive\")\n",
    "for i in range(1,len(files)+1):\n",
    "    img=cv2.imread(\"positive//1({}).jpg\".format(i))\n",
    "    blurred=cv2.GaussianBlur(img,(7,7),1)\n",
    "    grayscale=cv2.cvtColor(blurred,cv2.COLOR_BGR2GRAY)\n",
    "    ret,threshold = cv2.threshold(grayscale,100,255,cv2.THRESH_BINARY)\n",
    "    resize=cv2.resize(threshold,(40,40))\n",
    "    reshaped=resize.reshape(-1)\n",
    "    positiveImages.append(reshaped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2\n",
    "**Reading in images that do not have a robot in the picture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "negativeImages=[]\n",
    "files=os.listdir(\"negative\")\n",
    "for i in range(1,len(files)+1):\n",
    "    img=cv2.imread(\"negative//1({}).jpg\".format(i))\n",
    "    blurred=cv2.GaussianBlur(img,(7,7),1)\n",
    "    grayscale=cv2.cvtColor(blurred,cv2.COLOR_BGR2GRAY)\n",
    "    ret,threshold = cv2.threshold(grayscale,100,255,cv2.THRESH_BINARY)\n",
    "    resize=cv2.resize(threshold,(40,40))\n",
    "    reshaped=resize.reshape(-1)\n",
    "    negativeImages.append(reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2ac1ea07070>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(positiveImages[17].reshape(40,40),cmap=\"binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 \n",
    "**Labelling images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive=pd.DataFrame(positiveImages)\n",
    "positive[\"y\"]=1\n",
    "negative=pd.DataFrame(negativeImages)\n",
    "negative[\"y\"]=0\n",
    "resulting=pd.concat([positive,negative])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4\n",
    "**Split data into test and training inputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(resulting.drop(\"y\",axis=1),resulting.y,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5\n",
    "**First trained models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.925"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=1).fit(X_train,y_train)\n",
    "prediction=model.predict(X_test)\n",
    "accuracy_score(prediction,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.975"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier().fit(X_train,y_train)\n",
    "prediction=rf.predict(X_test)\n",
    "accuracy_score(prediction,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6\n",
    "\n",
    "**Detection on video**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('ar_tag.avi')\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    try:\n",
    "        height,width,dimension=frame.shape\n",
    "    except:\n",
    "        break\n",
    "    blurred=cv2.GaussianBlur(frame,(7,7),3)\n",
    "    grayscale=cv2.cvtColor(blurred,cv2.COLOR_BGR2GRAY)\n",
    "    ret,threshold = cv2.threshold(grayscale,100,255,cv2.THRESH_BINARY)\n",
    "    resize=cv2.resize(threshold,(40,40))\n",
    "    reshaped=resize.reshape(-1)\n",
    "    step=pd.DataFrame(data=[reshaped])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7\n",
    "\n",
    "**Location on image**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For locating objects on images with OpenCV and machine learning one of the methods actually is to train Haar Classifiers. For this we need images, that do not contain the object and image that contain. We need to show the location, where the object is situated.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
